{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa72aa5-a0a5-4304-926c-ca7ec2bef604",
   "metadata": {},
   "source": [
    "Simplified Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab15793-7cf5-487b-9d8f-1f3650185c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43,0.15,0.89], #\"Your\"  x^1\n",
    "    [0.55,0.87,0.66], #\"Journey\" x^2\n",
    "    [0.57,0.85,0.64], #\"Starts\"  x^3\n",
    "    [0.22,0.58,0.33], #\"with\"  x^4\n",
    "    [0.77,0.25,0.10], #\"one\"  x^5\n",
    "    [0.05,0.80,0.55] #\"step\"  x^6 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8177a7be-a882-4719-992d-9ecb82025ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_query = inputs[1]\n",
    "input_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdd3637-cca1-43ff-80c7-ceb0b22bedcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4300, 0.1500, 0.8900])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = inputs[0]\n",
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5708b17d-7138-4e9a-87f9-001f320d2d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5500*0.4300 +  0.8700 * 0.1500 + 0.6600*0.8900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0575de78-2d2b-4f6e-87e2-5b78495b7b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9544)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(input_query,input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978bd73a-2c4e-43ab-a31c-f3636dba7906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8434)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "res = torch.dot(inputs[i],input_query)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efd68e85-3f11-4270-91f0-4858b589bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores = torch.empty(inputs.shape[0])\n",
    "for i,x_i in enumerate(inputs):\n",
    "    attn_scores[i] = torch.dot(query,x_i)\n",
    "attn_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963e8b20-4a29-486e-b9a6-29494f0a66ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_tmp = attn_scores / attn_scores.sum()\n",
    "attn_weights_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b03c4d1-74ee-4179-ae17-f2ffff79fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x)/ torch.exp(x).sum(dim=0)\n",
    "softmax_naive(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a62fa18e-1881-4a4c-99f6-2dad1b703617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores,dim=0)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad1eb092-f297-47ab-9389-a32425d02863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    #print(f\"{attn_weights_2[i]} --> {inputs[i]}\")\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a23209-3190-4530-834c-a971ca34ce3d",
   "metadata": {},
   "source": [
    "Computing self attention mechanism without trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e70588bb-bc7e-4ca3-af38-90522f8c2040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = torch.empty(6,6)\n",
    "\n",
    "for i,x_i in enumerate(inputs):\n",
    "    for j,x_j in enumerate(inputs):\n",
    "        attn_scores[i,j] = torch.dot(x_i,x_j)\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf89390d-fe80-498e-971a-31d37b0d3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb6be185-5a35-4b9d-b999-506575c48fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores,dim = 1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "537a2731-2500-4767-8f2d-bb5fbf3d1065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "all_context_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521abee-1449-4164-9507-a2d12d2351c9",
   "metadata": {},
   "source": [
    "Self Attetion with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e02444f-7a68-4485-9d51-141909054180",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3d43e9c-e475-48ba-b739-5818b61228d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in,d_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e1faa8d-43af-4c67-90ed-69f0ee4f7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.2961, 0.5166],\n",
       "        [0.2517, 0.6886],\n",
       "        [0.0740, 0.8665]], requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1121fc3f-ed99-47a0-92b4-2b842d5abd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1366, 0.1025],\n",
       "        [0.1841, 0.7264],\n",
       "        [0.3153, 0.6871]], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbc07f0b-b935-4043-9529-00e02a686464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4306, 1.4551], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43efcd06-9dca-4e04-b6e0-d89856fee00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "967265e5-0bf9-49cf-a734-b6a36a642462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1827, 0.3292],\n",
       "        [0.3275, 0.9642]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2e58767-5f55-45ec-ad7a-0280d7e8834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5802f667-dfe9-4052-a0ac-5a4d5e7a5218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8524, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_22 = torch.dot(query_2,keys_2)\n",
    "attn_score_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d39b77e9-811d-4f36-9d09-bd3944f3369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc6496ec-91bc-4e01-9035-6c7388f5dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5,dim=-1)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "461468b5-4dcb-41fb-868e-9f4b3e451dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88c62bf8-41a4-4e92-bceb-a0cd564a1b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3061, 0.8210], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494f108-f4ee-47d9-9d5b-f84115dbab67",
   "metadata": {},
   "source": [
    "Self attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99c484bc-0c67-4ae8-8d11-b9ae8368bb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2996, 0.8053],\n",
       "        [0.3061, 0.8210],\n",
       "        [0.3058, 0.8203],\n",
       "        [0.2948, 0.7939],\n",
       "        [0.2927, 0.7891],\n",
       "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self,d_in,d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in,d_out))\n",
    "        self.d_k = self.W_key.shape[1]\n",
    "\n",
    "    def forward(self,x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in,d_out)\n",
    "sa_v1(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5022a-4368-4680-90d8-ef9b5e73d1fb",
   "metadata": {},
   "source": [
    "Better way of implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97d99a91-b0d0-46e7-82a6-d6785f097db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5337, -0.1051],\n",
       "        [-0.5323, -0.1080],\n",
       "        [-0.5323, -0.1079],\n",
       "        [-0.5297, -0.1076],\n",
       "        [-0.5311, -0.1066],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self,d_in,d_out,qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in,d_out,bias = qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in,d_out,bias = qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in,d_out,bias = qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "    def forward(self,x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v2 = SelfAttention_v2(d_in,d_out)\n",
    "sa_v2(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869d75d-a54b-4924-ba3a-7cce2156e88d",
   "metadata": {},
   "source": [
    "Next :Applying causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debdaa9-d526-4a96-82f5-c464101bbff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11abdc0-ff99-4870-9cde-31df643f200a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da7b29-89b1-4d82-abf9-6f56b255ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cc80d-c22a-4bc8-8ac1-43cd0b7b68ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
